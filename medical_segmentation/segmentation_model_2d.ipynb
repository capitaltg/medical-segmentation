{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IXsrwBeS04D"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras_unet.models import custom_unet\n",
    "import keras.backend as K\n",
    "\n",
    "import awscli\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-F4SuSkeTJcq"
   },
   "outputs": [],
   "source": [
    "!cat /content/drive/My\\ Drive/config/awscli.ini\n",
    "!export AWS_SHARED_CREDENTIALS_FILE=/content/drive/My\\ Drive/config/awscli.ini\n",
    "path = \"/content/drive/My Drive/config/awscli.ini\"\n",
    "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = path\n",
    "\n",
    "!aws s3 cp s3://medical-image-segmentation/lungs/70-10-20/train.zip .\n",
    "!aws s3 cp s3://medical-image-segmentation/lungs/70-10-20/val.zip .\n",
    "!aws s3 cp s3://medical-image-segmentation/lungs/70-10-20/test.zip .\n",
    "!aws s3 cp s3://medical-image-segmentation/lungs/70-10-20/train-output.zip .\n",
    "!aws s3 cp s3://medical-image-segmentation/lungs/70-10-20/val-output.zip .\n",
    "!aws s3 cp s3://medical-image-segmentation/lungs/70-10-20/test-output.zip .\n",
    "\n",
    "!unzip train.zip\n",
    "!unzip val.zip\n",
    "!unzip test.zip\n",
    "!unzip train-output.zip\n",
    "!unzip val-output.zip\n",
    "!unzip test-output.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUWNxZ_jbvjm",
    "outputId": "20bedb08-cae0-436c-caec-ab15a915dc65"
   },
   "outputs": [],
   "source": [
    "SEED = 909\n",
    "BATCH_SIZE_TRAIN = 6\n",
    "BATCH_SIZE_VAL = 6\n",
    "BATCH_SIZE_TEST = 6\n",
    "IMAGE_HEIGHT = 512\n",
    "IMAGE_WIDTH = 512\n",
    "IMG_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "NUM_TRAIN = 6651\n",
    "NUM_VAL = 932\n",
    "NUM_TEST = 1950\n",
    "\n",
    "def create_train(img_path, mask_path, batch_size=4):\n",
    "    data_gen_args = dict(rescale=1./255)\n",
    "    img_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    img_generator = img_datagen.flow_from_directory(img_path, target_size=IMG_SIZE,\n",
    "                                                    class_mode=None, color_mode='grayscale',\n",
    "                                                    batch_size=batch_size, seed=SEED)\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_directory(mask_path, target_size=IMG_SIZE,\n",
    "                                                      class_mode=None, color_mode='grayscale',\n",
    "                                                      batch_size=batch_size, seed=SEED)\n",
    "    return zip(img_generator, mask_generator)\n",
    "\n",
    "TRAIN_IMG_PATH = os.path.join('train-output', 'images')\n",
    "TRAIN_MASK_PATH = os.path.join('train-output', 'masks')\n",
    "\n",
    "VAL_IMG_PATH = os.path.join('val-output', 'images')\n",
    "VAL_MASK_PATH = os.path.join('val-output', 'masks')\n",
    "\n",
    "TEST_IMG_PATH = os.path.join('test-output', 'images')\n",
    "TEST_MASK_PATH = os.path.join('test-output', 'masks')\n",
    "\n",
    "TRAIN_GENERATOR = create_train(TRAIN_IMG_PATH, TRAIN_MASK_PATH, BATCH_SIZE_TRAIN)\n",
    "VAL_GENERATOR = create_train(VAL_IMG_PATH, VAL_MASK_PATH, BATCH_SIZE_TRAIN)\n",
    "TEST_GENERATOR = create_train(TEST_IMG_PATH, TEST_MASK_PATH, BATCH_SIZE_TRAIN)\n",
    "\n",
    "NUM_OF_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdE3oUG70cOn"
   },
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    \"\"\"\n",
    "    Displays an image, its corresponding mask, and the predicted mask\n",
    "    Args:\n",
    "        display_list (list): list containing image array, mask array, and\n",
    "                             prediction array in that order\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = ['Input', 'True Mask', 'Predicted Mask']\n",
    "    for i, array in enumerate(display_list):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(array), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def show_prediction(datagen, num=1):\n",
    "    \"\"\"\n",
    "    Generates images, masks, and predictions and calls display function\n",
    "    Args:\n",
    "        datagen (generator): generates images and corresponding masks\n",
    "        num (num): the number of image/mask/pred sets to be displayed\n",
    "    \"\"\"\n",
    "    for i in range(0, num):\n",
    "        image, mask = next(datagen)\n",
    "        pred_mask = MODEL.predict(image)[0] > 0.5\n",
    "        display([image[0], mask[0], pred_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GFq3_6xb0fg5",
    "outputId": "a7566f44-7eb3-457f-d7a6-bb888a29e573"
   },
   "outputs": [],
   "source": [
    "show_prediction(TRAIN_GENERATOR, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qTT3-ZGce_5"
   },
   "outputs": [],
   "source": [
    "def dice_loss(targets, inputs, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Computes the dice loss given targets and predictions\n",
    "    Args:\n",
    "        targets (array): the ground truth masks\n",
    "        inputs (array): the predicted masks\n",
    "        smooth (num): additional overlapping surface area\n",
    "    Returns:\n",
    "        the dice loss value\n",
    "    \"\"\"\n",
    "    inputs = K.flatten(inputs)\n",
    "    targets = K.flatten(targets)\n",
    "    intersection = K.sum(targets * inputs)\n",
    "    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
    "    return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqhmaTWIcmR5"
   },
   "outputs": [],
   "source": [
    "MODEL = custom_unet(\n",
    "    input_shape=(512, 512, 1),\n",
    "    use_batch_norm=True,\n",
    "    num_classes=1,\n",
    "    filters=64,\n",
    "    dropout=0.25,\n",
    "    output_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i25Af9iZcpSe"
   },
   "outputs": [],
   "source": [
    "STATS = [dice_loss, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "EPOCH_STEP_TRAIN = NUM_TRAIN // BATCH_SIZE_TRAIN\n",
    "EPOCH_STEP_VAL = NUM_VAL // BATCH_SIZE_VAL\n",
    "EPOCH_STEP_TEST = NUM_TEST // BATCH_SIZE_TEST\n",
    "model.compile(optimizer='adam', loss=dice_loss, metrics=STATS, run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIl1nGi4csEY",
    "outputId": "bf8269cc-9b0f-464d-8ed0-00eeac8e49ac"
   },
   "outputs": [],
   "source": [
    "MODEL.fit_generator(generator=TRAIN_GENERATOR,\n",
    "                    steps_per_epoch=EPOCH_STEP_TRAIN,\n",
    "                    validation_data=VAL_GENERATOR,\n",
    "                    validation_steps=EPOCH_STEP_VAL,\n",
    "                    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yAzkGzfddloE"
   },
   "outputs": [],
   "source": [
    "MODEL.save(f'drive/MyDrive/UNET5-A99-P93-R88-{IMAGE_HEIGHT}_{IMAGE_WIDTH}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRtNTDALUnKh"
   },
   "outputs": [],
   "source": [
    "MODEL = keras.models.load_model(f'drive/MyDrive/UNET4-A99-P93-R88-{IMAGE_HEIGHT}_{IMAGE_WIDTH}.h5', custom_objects={\"DiceLoss\": dice_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOwsL1sYNqa7"
   },
   "outputs": [],
   "source": [
    "def dice_gen(img_path, mask_path, batch_size=4):\n",
    "    \"\"\"\n",
    "    Creates a data generator that does not shuffle data\n",
    "    Args:\n",
    "        img_path (str): path to folder contaning images\n",
    "        mask_path (str): path to folder containing masks\n",
    "        batch_size (num): the generator batch size\n",
    "    Returns:\n",
    "        a generator for images and corresponding masks\n",
    "    \"\"\"\n",
    "    data_gen_args = dict(rescale=1./255)\n",
    "    img_gen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_gen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    img_generator = img_gen.flow_from_directory(img_path, target_size=IMG_SIZE, class_mode=None,\n",
    "                                                color_mode='grayscale', batch_size=batch_size,\n",
    "                                                seed=SEED, shuffle=False)\n",
    "\n",
    "    mask_generator = mask_gen.flow_from_directory(mask_path, target_size=IMG_SIZE, class_mode=None,\n",
    "                                                  color_mode='grayscale', batch_size=batch_size,\n",
    "                                                  seed=SEED, shuffle=False)\n",
    "    return img_generator, mask_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GV2QFe5NOg1I"
   },
   "outputs": [],
   "source": [
    "from pydicom import dcmread\n",
    "import statistics\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "# make sure metrics.py and lookup_tables.py is uploaded into runtime\n",
    "from metrics import compute_surface_distances, compute_surface_dice_at_tolerance\n",
    "\n",
    "def get_distances(path):\n",
    "    \"\"\"\n",
    "    Gets the voxel spacing values for images\n",
    "    Args:\n",
    "        path (str): path to folder containing images in dicom format\n",
    "    Returns:\n",
    "        dictionary with image path as keys and tuple of dimensions (x, y) as values\n",
    "    \"\"\"\n",
    "    distances = {}\n",
    "    for subdir in listdir(path):\n",
    "    for image in listdir(join(path, subdir, \"images\")):\n",
    "        dimensions = dcmread(join(path, subdir, \"images\", image)).PixelSpacing\n",
    "        png_name = \"lung_l/\" + subdir + \"-\" + image + \".png\"\n",
    "        distances[png_name] = [d for d in dimensions]\n",
    "    return distances\n",
    "\n",
    "def get_surface_dice_values(img_path, mask_path, batch_size, iterations, pixel_distances):\n",
    "    \"\"\"\n",
    "    Computes the surface dice scores for each image\n",
    "    Args:\n",
    "        img_path (str): path to folder containing images\n",
    "        mask_path (str): path to folder containing masks\n",
    "        batch_size (num): batch size of generator\n",
    "        iterations (num): number of batches within dataset\n",
    "        pixel_distances (dict): image name (key) and pixel spacing (value) pairs\n",
    "    Returns:\n",
    "        a list of surface dice scores\n",
    "    \"\"\"\n",
    "    index = 0\n",
    "    dice_list = []\n",
    "    image_gen, mask_gen = dice_gen(img_path, mask_path, batch_size)\n",
    "    files = image_gen.filenames\n",
    "\n",
    "    for i in range(iterations):\n",
    "    image, mask = next(image_gen), next(mask_gen)\n",
    "    pred_masks = model.predict(image)\n",
    "\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        pred_mask = pred_masks[j] > 0.5\n",
    "        bool_mask = mask[j].astype(bool)\n",
    "        mask_gt = bool_mask.reshape((512, 512))\n",
    "        predicted_mask = pred_mask.reshape((512, 512))\n",
    "\n",
    "        surface_distances = compute_surface_distances(mask_gt, predicted_mask, pixel_distances[files[index]])\n",
    "        surface_dice = compute_surface_dice_at_tolerance(surface_distances, 1.9)\n",
    "\n",
    "        dice_list.append(surface_dice)\n",
    "        index += 1\n",
    "    return dice_list\n",
    "  \n",
    "def compute_surface_dice_stats(dice_list):\n",
    "    \"\"\"\n",
    "    Computes summary statistics for surface dice scores\n",
    "    Args:\n",
    "        dice_list (list): list of surface_dice scores\n",
    "    Returns:\n",
    "        mean, median, standard deviation tuple for input surface dice scores\n",
    "    \"\"\"\n",
    "    filtered_dice_list = []\n",
    "    for val in dice_list:\n",
    "    if not math.isnan(val):\n",
    "        filtered_dice_list.append(val)\n",
    "    filtered_dice_list.sort()\n",
    "    mean = sum(filtered_dice_list) / len(filtered_dice_list)\n",
    "    median = filtered_dice_list[len(filtered_dice_list) // 2]\n",
    "    std_dev = statistics.stdev(filtered_dice_list)\n",
    "    return mean, median, std_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_eb6QiArO3XZ"
   },
   "outputs": [],
   "source": [
    "# split can be either train, val or test\n",
    "\n",
    "def surface_dice(split):\n",
    "    \"\"\"\n",
    "    Computes surface dice summary statistics depending on split\n",
    "    Args:\n",
    "        split (str): train, test, or val\n",
    "    Returns:\n",
    "        surface dice summary statistics for images in split\n",
    "    \"\"\"\n",
    "    if split == \"train\":\n",
    "        img_path, mask_path = TRAIN_IMG_PATH, TRAIN_MASK_PATH\n",
    "        batch_size, iterations = BATCH_SIZE_TRAIN, EPOCH_STEP_TRAIN\n",
    "    elif split == \"val\":\n",
    "        img_path, mask_path = VAL_IMG_PATH, VAL_MASK_PATH\n",
    "        batch_size, iterations = BATCH_SIZE_VAL, EPOCH_STEP_VAL\n",
    "    elif split == \"test\":\n",
    "        img_path, mask_path = TEST_IMG_PATH, TEST_MASK_PATH\n",
    "        batch_size, iterations = BATCH_SIZE_TEST, EPOCH_STEP_TEST\n",
    "    else:\n",
    "        assert False, \"invalid split\"\n",
    "\n",
    "    pixel_distances = get_distances(split)\n",
    "    dice_list = get_surface_dice_values(img_path, mask_path, batch_size, iterations, pixel_distances)\n",
    "    return compute_surface_dice_stats(dice_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a93327ZiVSee",
    "outputId": "6b2923b9-836f-4f8c-bd32-157864455370"
   },
   "outputs": [],
   "source": [
    "summary_stats = surface_dice(\"val\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training_segmentation_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
